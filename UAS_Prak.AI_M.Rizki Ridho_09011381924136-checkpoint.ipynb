{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "778351a0",
   "metadata": {},
   "source": [
    "# UAS Praktikum Kecerdasan Buatan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e158c39",
   "metadata": {},
   "source": [
    "### Nama : M. Rizki Ridho\n",
    "### NIM : 09011381924136\n",
    "### Kelas : SK 5 Unggulan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923c4d02",
   "metadata": {},
   "source": [
    "Soal:\n",
    "\n",
    "Dengan menggunakan data MNIST (Hand writing digit dataset) lakukan proses klasifikasi menggunakan metode pembelajaran mesin Jaringan Syaraf Tiruan, Support Vector Machine, dan Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35d0891",
   "metadata": {},
   "source": [
    "Link Reference :\n",
    "https://github.com/atanumaulik/ANN_MNIST/blob/main/ann_MINST.ipynb\n",
    "\n",
    "https://github.com/vneogi199/Handwritten-Digit-Recognition-Using-Random-Forest/blob/master/Handwritten%20Digit%20Classification.ipynb\n",
    "\n",
    "https://www.kaggle.com/nishan192/mnist-digit-recognition-using-svm/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7035f4ad",
   "metadata": {},
   "source": [
    "### Metode ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32a7436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special # needed to use the sigmoid activation function expit()\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa230cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\") #reading the csv files using pandas\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f069a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes,learningrate):\n",
    "        \n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # link weight matrices, weights sampled from a normal distribution\n",
    "        # np.random.normal (mean:0 ,std: 1/sqrt (of incoming links),(size : int or tuple of ints))\n",
    "        \n",
    "        self.wih = np.random.normal(0.0, pow (self.inodes,-0.5), (self.hnodes,self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes,self.hnodes))\n",
    "        \n",
    "        # Activation function : sigmoid: expit(x), imported from scipy.special\n",
    "        \n",
    "        self.activation_function = lambda x : scipy.special.expit(x)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        \n",
    "        # Converting inputs into a 2D array\n",
    "        inputs = np.array(inputs_list, ndmin = 2).T  # .T performs transpose\n",
    "        targets = np.array(targets_list, ndmin = 2).T\n",
    "        \n",
    "        # Propagating the input signals forward\n",
    "        # Calculate signals into hidden layer : dot product of weight and input matrices\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        \n",
    "        # Calculate signals emerging from hidden layer : sigmoid activation function applied\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        # Calculate signals into final output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        # Calculate signals out of final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        #  Calculation of errors\n",
    "        output_errors = targets - final_outputs\n",
    "        \n",
    "        # Backpropagation: adjustments of weights based on output errors\n",
    "        \n",
    "        # Hidden layer errors : output layer errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # updating weights between hidden and output layers\n",
    "        # Delta W_jk = lr * [E_k * sigmoid(O_k) * (1-sigmoid(O_k))] * [O_j]\n",
    "        self.who += self.lr*np.dot((output_errors*final_outputs*(1.0 - final_outputs)), np.transpose(hidden_outputs))\n",
    "        \n",
    "        # Updating weights between input and hidden layers\n",
    "        self.wih += self.lr*np.dot((hidden_errors*hidden_outputs*(1.0 - hidden_outputs)), np.transpose(inputs))\n",
    "        \n",
    "         \n",
    "    \n",
    "    # Query the neural network, i.e. forward propagate the inputs\n",
    "    def query(self, inputs_list):\n",
    "        \n",
    "        # Convert input list to 2-D array\n",
    "        inputs = np.array(inputs_list, ndmin = 2).T # .T performs transpose\n",
    "        \n",
    "        # Signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "         \n",
    "        # Calculate signals out of the hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # Signals into output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        # Signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a379932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Create instance of a neural network\n",
    "n = NeuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4714bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data from MNIST csv file\n",
    "training_data_file = open(\"/home/atanu/Desktop/mlds/codes/ann_MNIST/mnist_train.csv\",\"r\")\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d6ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the network\n",
    "\n",
    "epochs = 5 # The number of times the training data is used for training\n",
    "t0 = time.process_time() # Starting clock to measure time\n",
    "for e in range(epochs):\n",
    "    for record in training_data_list:\n",
    "        all_values = record.split(',')\n",
    "        inputs = np.asfarray(all_values[1:])/255.0*0.99+0.01  # Scale and shift the inputs\n",
    "        targets = np.zeros(output_nodes) + 0.01\n",
    "        targets[int(all_values[0])]=0.99 # all_values[0] is the target label for this record\n",
    "        n.train(inputs,targets)\n",
    "t1 = time.process_time()-t0\n",
    "print('Training time for {} epoch(s) is {:.1f} s'.format(epochs,t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16215e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the network\n",
    "\n",
    "test_data_file = open(\"/home/atanu/Desktop/mlds/codes/ann_rashid/mnist_test.csv\",\"r\")\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e69b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing against the full data set\n",
    "\n",
    "t2 = time.process_time()\n",
    "scorecard = []\n",
    "for record in test_data_list:\n",
    "    all_values = record.split(',')\n",
    "    correct_label = int(all_values[0]) # First number in the list\n",
    "    #print(correct_label,  'correct label')\n",
    "    inputs = np.asfarray(all_values[1:])/255.0*0.99+0.01 #rescaling inputs\n",
    "    outputs = n.query(inputs) # query the network\n",
    "    label = np.argmax(outputs)\n",
    "    #print(label, \"network's answer\")\n",
    "    if label ==correct_label:\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        scorecard.append(0)\n",
    "#print(scorecard)\n",
    "\n",
    "t3 = time.process_time()-t2\n",
    "\n",
    "\n",
    "# Calculate the performance score\n",
    "scorecard_array=np.asarray(scorecard)\n",
    "performance=scorecard_array.sum()/scorecard_array.size\n",
    "print(\"No. of input nodes : {}\".format(input_nodes))\n",
    "print(\"No. of hidden nodes : {}\".format(hidden_nodes))\n",
    "print(\"No. of output nodes : {}\".format(output_nodes))\n",
    "print(\"Time taken for testing is {:.1f} s\".format(t3))\n",
    "print(\"After a training session of {} epoch(s), performance = {} \".format(epochs, performance))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea92532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio # Loads data from png image files\n",
    "\n",
    "# test the neural network with our own images\n",
    "\n",
    "# load image data from png files into an array\n",
    "\n",
    "img_array = imageio.imread('/home/atanu/Desktop/mlds/codes/ann_MNIST/2828_my_own_2.png', as_gray=True)\n",
    "    \n",
    "# reshape from 28x28 to list of 784 values, invert values\n",
    "img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "# then scale data to range from 0.01 to 1.0\n",
    "img_data = ((img_data / 255.0) * 0.99) + 0.01\n",
    "print(\"min = \", np.min(img_data))\n",
    "print(\"max = \", np.max(img_data))\n",
    "#print(img_data)\n",
    "\n",
    "# plot image\n",
    "plt.imshow(img_data.reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# query the network\n",
    "outputs = n.query(img_data)\n",
    "print (outputs)\n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = np.argmax(outputs)\n",
    "print(\"Network says \", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd53c5",
   "metadata": {},
   "source": [
    "### Metode SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d302dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b71d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\") #reading the csv files using pandas\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d7bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape # print the dimension or shape of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2184873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape # print the dimension or shape of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ae8b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head() # printing first five columns of train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043dc20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head() # printing first five columns of test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9302493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are no missing values in the dataset \n",
    "\n",
    "train_data.isnull().sum().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84103b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.isnull().sum().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427f2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce8e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f03fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "print(\"Dimensions: \",test_data.shape, \"\\n\")\n",
    "\n",
    "# data types\n",
    "print(test_data.info())\n",
    "\n",
    "# head\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f890d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "print(\"Dimensions: \",train_data.shape, \"\\n\")\n",
    "\n",
    "# data types\n",
    "print(train_data.info())\n",
    "\n",
    "# head\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112e64b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.columns)\n",
    "print(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bf6267",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = list(np.sort(train_data['label'].unique()))\n",
    "print(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b648ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualizing the number of class and counts in the datasets\n",
    "\n",
    "\n",
    "sns.countplot(train_data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualizing the number of class and counts in the datasets\n",
    "plt.plot(figure = (16,10))\n",
    "g = sns.countplot( train_data[\"label\"], palette = 'icefire')\n",
    "plt.title('NUmber of digit classes')\n",
    "train_data.label.astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57372f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting some samples as well as converting into matrix\n",
    "\n",
    "three = train_data.iloc[7, 1:]\n",
    "three.shape\n",
    "three = three.values.reshape(28,28)\n",
    "plt.imshow(four, cmap='gray')\n",
    "plt.title(\"Digit 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "eight = train_data.iloc[10, 1:]\n",
    "eight.shape\n",
    "eight = eight.values.reshape(28, 28)\n",
    "plt.imshow(seven, cmap='gray')\n",
    "plt.title(\"Digit 7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acdc075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average feature values\n",
    "round(train_data.drop('label', axis=1).mean(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c86eb",
   "metadata": {},
   "source": [
    "Dalam hal ini, nilai rata-rata tidak terlalu bervariasi (misalnya memiliki perbedaan dalam urutan besarnya). Namun demikian, lebih baik untuk mengubah skala mereka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea35350",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separating the X and Y variable\n",
    "\n",
    "y = train_data['label']\n",
    "\n",
    "## Dropping the variable 'label' from X variable \n",
    "X = train_data.drop(columns = 'label')\n",
    "\n",
    "## Printing the size of data \n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c5f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalization\n",
    "\n",
    "X = X/255.0\n",
    "test_data = test_data/255.0\n",
    "\n",
    "print(\"X:\", X.shape)\n",
    "print(\"test_data:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f13ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features\n",
    "from sklearn.preprocessing import scale\n",
    "X_scaled = scale(X)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.3, train_size = 0.2 ,random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc141d0",
   "metadata": {},
   "source": [
    "**Model Building**\n",
    "\n",
    "Mari kita buat dua model dasar - linier dan non-linier dengan hyperparameter default, dan bandingkan akurasinya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5451871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model\n",
    "\n",
    "model_linear = SVC(kernel='linear')\n",
    "model_linear.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = model_linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d3283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix and accuracy\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "# cm\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e2a386",
   "metadata": {},
   "source": [
    "Model linier memberikan kira-kira. akurasi 91%. Mari kita lihat model yang cukup non-linier dengan hyperparameter yang dipilih secara acak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-linear model\n",
    "# using rbf kernel, C=1, default value of gamma\n",
    "\n",
    "# model\n",
    "non_linear_model = SVC(kernel='rbf')\n",
    "\n",
    "# fit\n",
    "non_linear_model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = non_linear_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd900bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix and accuracy\n",
    "\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "# cm\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1a852b",
   "metadata": {},
   "source": [
    "Model non-linear memberikan kira-kira. akurasi 93%. Jadi, ke depan, mari kita pilih hyperparameter yang sesuai dengan model non-linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8260ba5d",
   "metadata": {},
   "source": [
    "**Grid Search: Hyperparameter Tuning**\n",
    "\n",
    "Let's now tune the model to find the optimal values of C and gamma corresponding to an RBF kernel. We'll use 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfcaaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 10)\n",
    "\n",
    "# specify range of hyperparameters\n",
    "# Set the parameters by cross-validation\n",
    "hyper_params = [ {'gamma': [1e-2, 1e-3, 1e-4],\n",
    "                     'C': [5,10]}]\n",
    "\n",
    "\n",
    "# specify model\n",
    "model = SVC(kernel=\"rbf\")\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = model, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'accuracy', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45e9df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdef81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting C to numeric type for plotting on x-axis\n",
    "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
    "\n",
    "# # plotting\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "# subplot 1/3\n",
    "plt.subplot(131)\n",
    "gamma_01 = cv_results[cv_results['param_gamma']==0.01]\n",
    "\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.01\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "# subplot 2/3\n",
    "plt.subplot(132)\n",
    "gamma_001 = cv_results[cv_results['param_gamma']==0.001]\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "# subplot 3/3\n",
    "plt.subplot(133)\n",
    "gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n",
    "\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.0001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a278a383",
   "metadata": {},
   "source": [
    "Dari plot di atas, kita dapat mengamati bahwa (dari gamma yang lebih tinggi ke yang lebih rendah / kiri ke kanan):\n",
    "\n",
    "Pada gamma yang sangat tinggi (0,01), model mencapai akurasi 100% pada data pelatihan, meskipun skor tesnya cukup rendah (<80%). Dengan demikian, modelnya overfitting.\n",
    "\n",
    "Pada gamma=0,001, skor pelatihan dan tes sebanding di sekitar C=1, meskipun model mulai overfit pada nilai C yang lebih tinggi\n",
    "\n",
    "Pada gamma=0,0001, model tidak overfit sampai C=10 tetapi mulai menunjukkan tanda-tanda pada C=100. Juga, nilai pelatihan dan tes sedikit lebih rendah daripada di gamma=0,001.\n",
    "\n",
    "Jadi, tampaknya kombinasi terbaik adalah gamma=0,001 dan C=15 (plot di tengah), yang memberikan akurasi pengujian tertinggi (~94%) sambil menghindari overfitting.\n",
    "\n",
    "Sekarang mari kita buat model akhir dan lihat performanya pada data pengujian."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc113f",
   "metadata": {},
   "source": [
    "Sekarang mari kita pilih hyperparameter terbaik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d268e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "best_score = model_cv.best_score_\n",
    "best_hyperparams = model_cv.best_params_\n",
    "\n",
    "print(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77874a41",
   "metadata": {},
   "source": [
    "**Membangun dan Mengevaluasi Model Akhir**\n",
    "\n",
    "Sekarang mari kita membangun dan mengevaluasi model akhir, yaitu model dengan akurasi pengujian tertinggi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578db145",
   "metadata": {},
   "source": [
    "**Kesimpulan**\n",
    " \n",
    "Akurasi yang dicapai dengan menggunakan kernel non-linear (~0.94)lebih tinggi daripada kernel linear (~0.91). Kita dapat menyimpulkan bahwa masalahnya sangat non-linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5748a1",
   "metadata": {},
   "source": [
    "### Metode Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77498a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27acabaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read train and test files\n",
    "train_file = pd.read_csv('train.csv')\n",
    "test_file = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33615ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view first 5 records of train_file\n",
    "train_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view first 5 records of test_file\n",
    "test_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580297fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of all digits that are going to be predicted\n",
    "np.sort(train_file.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0222a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the number of samples for training set and for validation set\n",
    "num_train,num_validation = int(len(train_file)*0.8),int(len(train_file)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16a8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train,num_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e8995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate training data from train_file\n",
    "x_train,y_train=train_file.iloc[:num_train,1:].values,train_file.iloc[:num_train,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58496171",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation,y_validation=train_file.iloc[num_train:,1:].values,train_file.iloc[num_train:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14495d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validation.shape)\n",
    "print(y_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1e031b",
   "metadata": {},
   "source": [
    "***Visualize Training Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093bb71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=3\n",
    "print(\"Label: \" + str(y_train[index]))\n",
    "plt.imshow(x_train[index].reshape((28,28)),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7957fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit a Random Forest classifier\n",
    "clf=RandomForestClassifier()\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b79f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict value of label using classifier\n",
    "prediction_validation = clf.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd2a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation Accuracy: \" + str(accuracy_score(y_validation,prediction_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458a9709",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation Confusion Matrix: \\n\" + str(confusion_matrix(y_validation,prediction_validation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efc6e5f",
   "metadata": {},
   "source": [
    "***Melihat Prediksi yang Salah***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948908e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=3\n",
    "print(\"Predicted \" + str(y_validation[y_validation!=prediction_validation][index]) + \" as \" + \n",
    "     str(prediction_validation[y_validation!=prediction_validation][index]))\n",
    "plt.imshow(x_validation[y_validation!=prediction_validation][index].reshape((28,28)),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e174c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict test data\n",
    "prediction_test = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f3ce9",
   "metadata": {},
   "source": [
    "***Melihat Prediksi untuk Test Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b4b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=5\n",
    "print(\"Predicted \" + str(prediction_test[index]))\n",
    "plt.imshow(x_test.iloc[index].values.reshape((28,28)),cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
